[
  {
    "name": "codeqai (fynnfluegge)",
    "description": "[é¡¹ç›®çº§] Local first semantic code search and chat | Leverage custom copilots with fine-tuning datasets from code in Alpaca, Conversational, Completion and Instruction formatã€‚æ¥æº: https://github.com/fynnfluegge/codeqai",
    "domain": "ai-llm",
    "tags": [
      "codellama",
      "faiss",
      "gpt",
      "huggingface",
      "langchain",
      "python",
      "stars-497",
      "github-fynnfluegge",
      "project-level"
    ],
    "genes": [
      {
        "title": "é¡¹ç›®æ¦‚è¿°",
        "content": "Local first semantic code search and chat | Leverage custom copilots with fine-tuning datasets from code in Alpaca, Conversational, Completion and Instruction format\n\næ¥æº: https://github.com/fynnfluegge/codeqai\nè¯­è¨€: Python\nStars: 497",
        "gene_type": "principle"
      },
      {
        "title": "å®‰è£…ä¸å¿«é€Ÿå¼€å§‹",
        "content": "pipx install codeqai",
        "gene_type": "snippet"
      },
      {
        "title": "é¡¹ç›®ç»“æ„",
        "content": "LICENSE\nREADME.md\ncodeqai\ncodeqai/__init__.py\ncodeqai/__main__.py\ncodeqai/app.py\ncodeqai/bootstrap.py\ncodeqai/cache.py\ncodeqai/codeparser.py\ncodeqai/config.py\ncodeqai/constants.py\ncodeqai/dataset_extractor.py\ncodeqai/embeddings.py\ncodeqai/llm.py\ncodeqai/repo.py\ncodeqai/streamlit.py\ncodeqai/treesitter\ncodeqai/utils.py\ncodeqai/vector_store.py\nconda-linux-64.lock",
        "gene_type": "pattern"
      },
      {
        "title": "ä½¿ç”¨æ–¹æ³•",
        "content": "",
        "gene_type": "snippet"
      },
      {
        "title": "æ ¸å¿ƒç‰¹æ€§",
        "content": "- ğŸ—’ï¸ &nbsp;Finetuning dataset generation\n  - export in Alpaca, conversational, instruction or completionn format \n- ğŸ” &nbsp;Semantic code search\n- ğŸ’¬ &nbsp;GPT-like chat with your codebase\n- âš™ï¸ &nbsp;Synchronize vector store and latest code changes with ease\n- ğŸ’» &nbsp;100% local embeddings and llms\n  - sentence-transformers, instructor-embeddings, llama.cpp, Ollama\n- ğŸŒ &nbsp;OpenAI, Azure OpenAI and Anthropic\n- ğŸŒ³ &nbsp;Treesitter integration\n\n> [!NOTE]  \n> There will be better results if the code is well documented. You might consider [doc-comments-ai](https://github.com/fynnfluegge/doc-c",
        "gene_type": "checklist"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 4.348178194366666
  },
  {
    "name": "codeqai/codeqai æ¨¡å—",
    "description": "[æ¨¡å—çº§] codeqai é¡¹ç›®çš„ codeqai æ¨¡å— (source)ã€‚æ¥æº: https://github.com/fynnfluegge/codeqai",
    "domain": "ai-llm",
    "tags": [
      "codellama",
      "faiss",
      "gpt",
      "huggingface",
      "langchain",
      "module-level",
      "source",
      "codeqai"
    ],
    "genes": [
      {
        "title": "codeqai æ¨¡å—è¯´æ˜",
        "content": "[![Build](https://github.com/fynnfluegge/codeqai/actions/workflows/build.yaml/badge.svg?branch=main)](https://github.com/fynnfluegge/codeqai/actions/workflows/build.yaml)\n[![Publish](https://github.com/fynnfluegge/codeqai/actions/workflows/publish.yaml/badge.svg)](https://github.com/fynnfluegge/codeqai/actions/workflows/publish.yaml)\n[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n\n</div>\n\n<div align=\"center\">\n\nGenerate datase",
        "gene_type": "principle"
      },
      {
        "title": "codeqai æ–‡ä»¶ç»“æ„",
        "content": "codeqai/__init__.py\ncodeqai/__main__.py\ncodeqai/app.py\ncodeqai/bootstrap.py\ncodeqai/cache.py\ncodeqai/codeparser.py\ncodeqai/config.py\ncodeqai/constants.py\ncodeqai/dataset_extractor.py\ncodeqai/embeddings.py\ncodeqai/llm.py\ncodeqai/repo.py\ncodeqai/streamlit.py\ncodeqai/treesitter\ncodeqai/treesitter/__init__.py",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.5785425554933328
  },
  {
    "name": "codeqai/datasets æ¨¡å—",
    "description": "[æ¨¡å—çº§] codeqai é¡¹ç›®çš„ datasets æ¨¡å— (source)ã€‚æ¥æº: https://github.com/fynnfluegge/codeqai",
    "domain": "ai-llm",
    "tags": [
      "codellama",
      "faiss",
      "gpt",
      "huggingface",
      "langchain",
      "module-level",
      "source",
      "datasets"
    ],
    "genes": [
      {
        "title": "datasets æ¨¡å—è¯´æ˜",
        "content": "æ¨¡å—è·¯å¾„: datasets/\nç±»å‹: source\næ–‡ä»¶æ•°: 3\n\nåŒ…å«æ–‡ä»¶:\n- datasets/alpaca_dataset.json\n- datasets/completion_dataset.json\n- datasets/conversational_dataset.json",
        "gene_type": "principle"
      },
      {
        "title": "datasets æ–‡ä»¶ç»“æ„",
        "content": "datasets/alpaca_dataset.json\ndatasets/completion_dataset.json\ndatasets/conversational_dataset.json",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.5785425554933328
  },
  {
    "name": "codeqai/tests æ¨¡å—",
    "description": "[æ¨¡å—çº§] codeqai é¡¹ç›®çš„ tests æ¨¡å— (test)ã€‚æ¥æº: https://github.com/fynnfluegge/codeqai",
    "domain": "testing",
    "tags": [
      "codellama",
      "faiss",
      "gpt",
      "huggingface",
      "langchain",
      "module-level",
      "test",
      "tests"
    ],
    "genes": [
      {
        "title": "tests æ¨¡å—è¯´æ˜",
        "content": "æ¨¡å—è·¯å¾„: tests/\nç±»å‹: test\næ–‡ä»¶æ•°: 5\n\nåŒ…å«æ–‡ä»¶:\n- tests/__init__.py\n- tests/conftest.py\n- tests/fixtures\n- tests/fixtures/vector_entries.py\n- tests/vector_store_test.py",
        "gene_type": "principle"
      },
      {
        "title": "tests æ–‡ä»¶ç»“æ„",
        "content": "tests/__init__.py\ntests/conftest.py\ntests/fixtures\ntests/fixtures/vector_entries.py\ntests/vector_store_test.py",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.5785425554933328
  }
]