[
  {
    "name": "mcp-client-for-ollama (jonigl)",
    "description": "[é¡¹ç›®çº§] A text-based user interface (TUI) client for interacting with MCP servers using Ollama. Features include agent mode, multi-server, model switching, streaming responses, tool management, human-in-the-loop, thinking mode, model params config, MCP prompts, custom system prompt and saved preferences. Built for developers working with local LLMs.ã€‚æ¥æº: https://github.com/jonigl/mcp-client-for-ollama",
    "domain": "ai-llm",
    "tags": [
      "agentic-ai",
      "ai",
      "command-line-tool",
      "generative-ai",
      "linux",
      "python",
      "stars-541",
      "github-jonigl",
      "project-level"
    ],
    "genes": [
      {
        "title": "é¡¹ç›®æ¦‚è¿°",
        "content": "MCP Client for Ollama (`ollmcp`) is a modern, interactive terminal application (TUI) for connecting local Ollama LLMs to one or more Model Context Protocol (MCP) servers, enabling advanced tool use and workflow automation. With a rich, user-friendly interface, it lets you manage tools, models, and server connections in real timeâ€”no coding required. Whether you're building, testing, or just exploring LLM tool use, this client streamlines your workflow with features like fuzzy autocomplete, advanced model configuration, MCP servers hot-reloading for development, and Human-in-the-Loop safety controls.",
        "gene_type": "principle"
      },
      {
        "title": "å®‰è£…ä¸å¿«é€Ÿå¼€å§‹",
        "content": "pip install --upgrade ollmcp\nollmcp",
        "gene_type": "snippet"
      },
      {
        "title": "é¡¹ç›®ç»“æ„",
        "content": "DEV.md\nLICENSE\nREADME.md\nSECURITY.md\ncli-package\ncli-package/README.md\ncli-package/ollmcp\ncli-package/pyproject.toml\ncli-package/tests\nmcp_client_for_ollama\nmcp_client_for_ollama/__init__.py\nmcp_client_for_ollama/__main__.py\nmcp_client_for_ollama/cli.py\nmcp_client_for_ollama/client.py\nmcp_client_for_ollama/config\nmcp_client_for_ollama/models\nmcp_client_for_ollama/prompts\nmcp_client_for_ollama/server\nmcp_client_for_ollama/tools\nmcp_client_for_ollama/utils",
        "gene_type": "pattern"
      },
      {
        "title": "ä½¿ç”¨æ–¹æ³•",
        "content": "Run with default settings:\n\n```bash\nollmcp\n```\n\n> If you don't provide any options, the client will use `auto-discovery` mode to find MCP servers from Claude's configuration.",
        "gene_type": "snippet"
      },
      {
        "title": "æ ¸å¿ƒç‰¹æ€§",
        "content": "- ğŸ¤– **Agent Mode**: Iterative tool execution when models request multiple tool calls, with a configurable loop limit to prevent infinite loops\n- ğŸŒ **Multi-Server Support**: Connect to multiple MCP servers simultaneously\n- ğŸš€ **Multiple Transport Types**: Supports STDIO, SSE, and Streamable HTTP server connections\n- ğŸ“‹ **MCP Prompts Support**: Browse, invoke, and manage prompts from MCP servers with argument collection, preview, and safe rollback\n- â˜ï¸ **Ollama Cloud Support**: Works seamlessly with Ollama Cloud models for tool calling, enabling access to powerful cloud-hosted models while usi",
        "gene_type": "checklist"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 4.366598632553284
  },
  {
    "name": "mcp-client-for-ollama/cli-package æ¨¡å—",
    "description": "[æ¨¡å—çº§] mcp-client-for-ollama é¡¹ç›®çš„ cli-package æ¨¡å— (source)ã€‚æ¥æº: https://github.com/jonigl/mcp-client-for-ollama",
    "domain": "ai-llm",
    "tags": [
      "agentic-ai",
      "ai",
      "command-line-tool",
      "generative-ai",
      "linux",
      "module-level",
      "source",
      "cli-package"
    ],
    "genes": [
      {
        "title": "cli-package æ¨¡å—è¯´æ˜",
        "content": "æ¨¡å—è·¯å¾„: cli-package/\nç±»å‹: source\næ–‡ä»¶æ•°: 7\n\nåŒ…å«æ–‡ä»¶:\n- cli-package/README.md\n- cli-package/ollmcp\n- cli-package/ollmcp/cli.py\n- cli-package/pyproject.toml\n- cli-package/tests\n- cli-package/tests/__init__.py\n- cli-package/tests/test_cli_import.py",
        "gene_type": "principle"
      },
      {
        "title": "cli-package æ–‡ä»¶ç»“æ„",
        "content": "cli-package/README.md\ncli-package/ollmcp\ncli-package/ollmcp/cli.py\ncli-package/pyproject.toml\ncli-package/tests\ncli-package/tests/__init__.py\ncli-package/tests/test_cli_import.py",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.593278906042628
  },
  {
    "name": "mcp-client-for-ollama/mcp_client_for_ollama æ¨¡å—",
    "description": "[æ¨¡å—çº§] mcp-client-for-ollama é¡¹ç›®çš„ mcp_client_for_ollama æ¨¡å— (source)ã€‚æ¥æº: https://github.com/jonigl/mcp-client-for-ollama",
    "domain": "ai-llm",
    "tags": [
      "agentic-ai",
      "ai",
      "command-line-tool",
      "generative-ai",
      "linux",
      "module-level",
      "source",
      "mcp_client_for_ollama"
    ],
    "genes": [
      {
        "title": "mcp_client_for_ollama æ¨¡å—è¯´æ˜",
        "content": "æ¨¡å—è·¯å¾„: mcp_client_for_ollama/\nç±»å‹: source\næ–‡ä»¶æ•°: 38\n\nåŒ…å«æ–‡ä»¶:\n- mcp_client_for_ollama/__init__.py\n- mcp_client_for_ollama/__main__.py\n- mcp_client_for_ollama/cli.py\n- mcp_client_for_ollama/client.py\n- mcp_client_for_ollama/config\n- mcp_client_for_ollama/config/__init__.py\n- mcp_client_for_ollama/config/defaults.py\n- mcp_client_for_ollama/config/manager.py\n- mcp_client_for_ollama/models\n- mcp_client_for_ollama/models/__init__.py",
        "gene_type": "principle"
      },
      {
        "title": "mcp_client_for_ollama æ–‡ä»¶ç»“æ„",
        "content": "mcp_client_for_ollama/__init__.py\nmcp_client_for_ollama/__main__.py\nmcp_client_for_ollama/cli.py\nmcp_client_for_ollama/client.py\nmcp_client_for_ollama/config\nmcp_client_for_ollama/config/__init__.py\nmcp_client_for_ollama/config/defaults.py\nmcp_client_for_ollama/config/manager.py\nmcp_client_for_ollama/models\nmcp_client_for_ollama/models/__init__.py\nmcp_client_for_ollama/models/config_manager.py\nmcp_client_for_ollama/models/manager.py\nmcp_client_for_ollama/prompts\nmcp_client_for_ollama/prompts/__init__.py\nmcp_client_for_ollama/prompts/content.py",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.593278906042628
  },
  {
    "name": "mcp-client-for-ollama/misc æ¨¡å—",
    "description": "[æ¨¡å—çº§] mcp-client-for-ollama é¡¹ç›®çš„ misc æ¨¡å— (source)ã€‚æ¥æº: https://github.com/jonigl/mcp-client-for-ollama",
    "domain": "ai-llm",
    "tags": [
      "agentic-ai",
      "ai",
      "command-line-tool",
      "generative-ai",
      "linux",
      "module-level",
      "source",
      "misc"
    ],
    "genes": [
      {
        "title": "misc æ¨¡å—è¯´æ˜",
        "content": "æ¨¡å—è·¯å¾„: misc/\nç±»å‹: source\næ–‡ä»¶æ•°: 16\n\nåŒ…å«æ–‡ä»¶:\n- misc/github-preview-correct-size.png\n- misc/github-preview.png\n- misc/ollmcp-demo.gif\n- misc/ollmcp-demo.svg\n- misc/ollmcp-hil-feature.png\n- misc/ollmcp-logo-512.png\n- misc/ollmcp-logo-white-background.min.svg\n- misc/ollmcp-logo-white-background.svg\n- misc/ollmcp-logo.svg\n- misc/ollmcp-model-configuration.png",
        "gene_type": "principle"
      },
      {
        "title": "misc æ–‡ä»¶ç»“æ„",
        "content": "misc/github-preview-correct-size.png\nmisc/github-preview.png\nmisc/ollmcp-demo.gif\nmisc/ollmcp-demo.svg\nmisc/ollmcp-hil-feature.png\nmisc/ollmcp-logo-512.png\nmisc/ollmcp-logo-white-background.min.svg\nmisc/ollmcp-logo-white-background.svg\nmisc/ollmcp-logo.svg\nmisc/ollmcp-model-configuration.png\nmisc/ollmcp-ollama-performance-metrics.png\nmisc/ollmcp-prompt-feature.png\nmisc/ollmcp-welcome.png\nmisc/ollmpc-model-selection.jpg\nmisc/ollmpc-tool-and-server-selection.jpg",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.593278906042628
  },
  {
    "name": "mcp-client-for-ollama/tests æ¨¡å—",
    "description": "[æ¨¡å—çº§] mcp-client-for-ollama é¡¹ç›®çš„ tests æ¨¡å— (test)ã€‚æ¥æº: https://github.com/jonigl/mcp-client-for-ollama",
    "domain": "testing",
    "tags": [
      "agentic-ai",
      "ai",
      "command-line-tool",
      "generative-ai",
      "linux",
      "module-level",
      "test",
      "tests"
    ],
    "genes": [
      {
        "title": "tests æ¨¡å—è¯´æ˜",
        "content": "æ¨¡å—è·¯å¾„: tests/\nç±»å‹: test\næ–‡ä»¶æ•°: 7\n\nåŒ…å«æ–‡ä»¶:\n- tests/__init__.py\n- tests/test_cleanup_race_condition.py\n- tests/test_config_manager.py\n- tests/test_connector.py\n- tests/test_hil_session.py\n- tests/test_server_discovery.py\n- tests/test_version.py",
        "gene_type": "principle"
      },
      {
        "title": "tests æ–‡ä»¶ç»“æ„",
        "content": "tests/__init__.py\ntests/test_cleanup_race_condition.py\ntests/test_config_manager.py\ntests/test_connector.py\ntests/test_hil_session.py\ntests/test_server_discovery.py\ntests/test_version.py",
        "gene_type": "pattern"
      }
    ],
    "version": 1,
    "usage_count": 0,
    "rating": 3.593278906042628
  }
]